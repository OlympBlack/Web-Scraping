# Projet de Scraping Web (BrainyQuote)

Une application full-stack de web scraping construite avec **Nuxt** (Frontend) et **FastAPI + Playwright** (Backend), int√©gr√©e avec **Supabase** pour la base de donn√©es et le stockage.

## üöÄ Liens de Production

*   **Frontend (Site Web)** : [https://web-scraper-snowy.vercel.app/](https://web-scraper-snowy.vercel.app/)
*   **Backend (API)** : [https://web-scraper-4luz.onrender.com](https://web-scraper-4luz.onrender.com) (Document√© ici pour r√©f√©rence, utilis√© par le frontend)

> [!IMPORTANT]
> **Attention lors du d√©ploiement du Backend** :
> Assurez-vous d'utiliser le **Runtime Docker** sur votre h√©bergeur (Render, Railway, etc.). N'utilisez PAS l'environnement "Python Native" ou "Shell" par d√©faut, car Playwright a besoin de d√©pendances syst√®me sp√©cifiques qui sont incluses dans notre `Dockerfile`.

---

## Fonctionnalit√©s
- **Scraping** : Extraction automatis√©e de citations et d'images depuis BrainyQuote.
- **Retour en temps r√©el** : Barre de progression et mises √† jour de statut en direct via Server-Sent Events (SSE).
- **Stockage** : Les images sont t√©l√©charg√©es, trait√©es et stock√©es dans Supabase Storage avec les types MIME corrects.
- **Base de donn√©es** : Les citations sont sauvegard√©es dans une base de donn√©es Postgres Supabase.

---

## Pr√©requis
- **Python 3.10+**
- **Node.js 18+**
- **Compte Supabase** avec un nouveau projet.

---

## Installation et Configuration (Local)

### 1. Configuration du Backend

Naviguez dans le dossier backend :
```bash
cd backend
```

Cr√©ez un environnement virtuel et installez les d√©pendances :
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate

# Installer les paquets
pip install -r requirements.txt
playwright install chromium
```

Cr√©ez un fichier `.env` dans `backend/` :
```ini
SUPABASE_URL=votre_url_projet_supabase
SUPABASE_KEY=votre_cle_anon_supabase
SUPABASE_SERVICE_ROLE_KEY=votre_cle_service_role
```

### 2. Configuration du Frontend

Naviguez dans le dossier frontend :
```bash
cd ../frontend
```

Installez les d√©pendances :
```bash
npm install
```

### 3. Configuration de Supabase

1.  **Base de donn√©es** : Cr√©ez une table nomm√©e `quotes`.
    ```sql
    create table quotes (
      id bigint generated by default as identity primary key,
      created_at timestamp with time zone default timezone('utc'::text, now()) not null,
      text text,
      author text,
      topic text,
      link text unique,
      image_url text
    );
    ```
2.  **Stockage** : Cr√©ez un bucket public nomm√© `quote-images`.

---

## Utilisation

### Lancer Localement

Vous avez besoin de deux terminaux.

**Terminal 1 : Backend**
```bash
cd backend
venv\Scripts\activate  # Windows
python run.py
```
*Le backend tourne sur http://127.0.0.1:8000*

**Terminal 2 : Frontend**
```bash
cd frontend
npm run dev
```
*Le frontend tourne sur http://localhost:3000*

**Utilisation** : Ouvrez l'URL du frontend, entrez un sujet (ex: "Success"), et cliquez sur "Scrape".

---

## D√©ploiement

### Frontend (Nuxt) - Vercel
Configurer la variable d'environnement :
*   `NUXT_PUBLIC_API_BASE`: `https://web-scraper-4luz.onrender.com`

### Backend (FastAPI) - Render
*   S√©lectionner **Docker** comme environnement de build.
*   Variables d'environnement : `SUPABASE_URL`, `SUPABASE_KEY`, `SUPABASE_SERVICE_ROLE_KEY`.
